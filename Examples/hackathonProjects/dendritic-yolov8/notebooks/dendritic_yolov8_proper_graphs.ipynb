{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dendritic YOLOv8: Proper PAI Graph Output\n",
    "\n",
    "This notebook produces the **correct graph format** as shown in Dendrite Recommendations.pdf:\n",
    "- Green line: Training scores\n",
    "- Orange line: Validation scores  \n",
    "- Blue/Red lines: What would have happened without dendrites\n",
    "- Vertical blue bars: Where dendrites were added\n",
    "\n",
    "## Setup\n",
    "1. **Runtime → Change runtime type → GPU**\n",
    "2. **Run cells in order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"In Colab: {IN_COLAB}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Installing dependencies...\")\n",
    "    !pip install -q ultralytics matplotlib pandas\n",
    "    !pip install -q perforatedai==3.0.7\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and GPU check\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.data import build_dataloader, build_yolo_dataset\n",
    "\n",
    "# PerforatedAI imports\n",
    "from perforatedai import globals_perforatedai as GPA\n",
    "from perforatedai import utils_perforatedai as UPA\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"\\nDevice: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Helper functions\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count total trainable parameters.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def get_yolo_dataloader(yolo_model, data_yaml='coco128.yaml', batch_size=16, mode='train'):\n",
    "    \"\"\"\n",
    "    Get a PyTorch dataloader from YOLO's data loading system.\n",
    "    \"\"\"\n",
    "    # Use YOLO's built-in data loading\n",
    "    from ultralytics.data.utils import check_det_dataset\n",
    "    data_dict = check_det_dataset(data_yaml)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        dataset = build_yolo_dataset(\n",
    "            yolo_model.model,\n",
    "            data_dict['train'],\n",
    "            batch=batch_size,\n",
    "            data=data_dict,\n",
    "            mode='train',\n",
    "            rect=False\n",
    "        )\n",
    "    else:\n",
    "        dataset = build_yolo_dataset(\n",
    "            yolo_model.model,\n",
    "            data_dict['val'],\n",
    "            batch=batch_size,\n",
    "            data=data_dict,\n",
    "            mode='val',\n",
    "            rect=True\n",
    "        )\n",
    "    \n",
    "    dataloader = build_dataloader(\n",
    "        dataset,\n",
    "        batch=batch_size,\n",
    "        workers=4,\n",
    "        shuffle=(mode == 'train')\n",
    "    )\n",
    "    return dataloader, data_dict\n",
    "\n",
    "print(\"Helper functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load YOLOv8n and initialize PerforatedAI\n",
    "\n",
    "# Load base model\n",
    "print(\"Loading YOLOv8n...\")\n",
    "yolo = YOLO('yolov8n.pt')\n",
    "model = yolo.model\n",
    "\n",
    "baseline_params = count_parameters(model)\n",
    "print(f\"Baseline parameters: {baseline_params / 1e6:.2f}M\")\n",
    "\n",
    "# Configure PerforatedAI\n",
    "print(\"\\nConfiguring PerforatedAI...\")\n",
    "GPA.pc.set_testing_dendrite_capacity(False)\n",
    "GPA.pc.set_verbose(True)\n",
    "GPA.pc.set_dendrite_update_mode(True)\n",
    "\n",
    "# Create PAI output directory\n",
    "os.makedirs('PAI', exist_ok=True)\n",
    "\n",
    "# Initialize PAI - this sets up tracking and enables dendrite addition\n",
    "# IMPORTANT: save_name determines where the graph is saved (PAI/save_name.png)\n",
    "model = UPA.initialize_pai(\n",
    "    model,\n",
    "    doing_pai=True,\n",
    "    save_name='PAI',  # Output will be PAI/PAI.png\n",
    "    maximizing_score=True,  # We're maximizing mAP, not minimizing loss\n",
    "    making_graphs=True\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "yolo.model = model\n",
    "\n",
    "dendritic_params = count_parameters(model)\n",
    "print(f\"\\nDendritic parameters (initial): {dendritic_params / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Setup optimizer through PAI tracker\n",
    "\n",
    "# PAI needs to manage the optimizer to reset it after restructuring\n",
    "GPA.pai_tracker.set_optimizer(optim.Adam)\n",
    "GPA.pai_tracker.set_scheduler(ReduceLROnPlateau)\n",
    "\n",
    "lr = 0.001\n",
    "optimArgs = {'params': model.parameters(), 'lr': lr}\n",
    "schedArgs = {'mode': 'max', 'patience': 3, 'factor': 0.5}\n",
    "\n",
    "optimizer, scheduler = GPA.pai_tracker.setup_optimizer(model, optimArgs, schedArgs)\n",
    "\n",
    "print(\"Optimizer and scheduler configured through PAI tracker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Training functions that track scores properly\n",
    "\n",
    "def train_one_epoch(model, yolo, device):\n",
    "    \"\"\"\n",
    "    Train for one epoch and return training accuracy/score.\n",
    "    Uses YOLO's built-in training for one epoch.\n",
    "    \"\"\"\n",
    "    # Use YOLO's training mechanism for one epoch\n",
    "    yolo.model = model\n",
    "    \n",
    "    # Train for 1 epoch\n",
    "    results = yolo.train(\n",
    "        data='coco128.yaml',\n",
    "        epochs=1,\n",
    "        imgsz=640,\n",
    "        batch=16,\n",
    "        device=device,\n",
    "        exist_ok=True,\n",
    "        verbose=False,\n",
    "        project='runs/train',\n",
    "        name='dendritic'\n",
    "    )\n",
    "    \n",
    "    model = yolo.model\n",
    "    \n",
    "    # Get training metrics (mAP50 from training)\n",
    "    # Note: YOLO computes validation metrics during training\n",
    "    train_map50 = float(results.results_dict.get('metrics/mAP50(B)', 0))\n",
    "    \n",
    "    return model, train_map50\n",
    "\n",
    "\n",
    "def validate_model(model, yolo, device):\n",
    "    \"\"\"\n",
    "    Validate model and return mAP50 score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    yolo.model = model\n",
    "    \n",
    "    results = yolo.val(\n",
    "        data='coco128.yaml',\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    val_map50 = float(results.box.map50) if results.box.map50 else 0.0\n",
    "    return val_map50\n",
    "\n",
    "print(\"Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Main training loop with proper PAI integration\n",
    "#\n",
    "# KEY POINTS for correct graph output:\n",
    "# 1. Call add_extra_score(train_score, 'train') after each training epoch\n",
    "# 2. Call add_validation_score(val_score, model) after validation\n",
    "# 3. Continue training until training_complete is True\n",
    "# 4. Reset optimizer when model is restructured\n",
    "#\n",
    "# The PAI tracker automatically:\n",
    "# - Tracks training and validation scores\n",
    "# - Detects plateaus and adds dendrites\n",
    "# - Saves graphs to PAI/PAI.png showing the characteristic pattern\n",
    "\n",
    "MAX_EPOCHS = 100  # Will stop early when PAI says training is complete\n",
    "\n",
    "print(\"Starting training with PerforatedAI integration...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "epoch = 0\n",
    "training_complete = False\n",
    "history = {'train_scores': [], 'val_scores': [], 'params': []}\n",
    "\n",
    "while not training_complete and epoch < MAX_EPOCHS:\n",
    "    print(f\"\\nEpoch {epoch + 1}/{MAX_EPOCHS}\")\n",
    "    \n",
    "    # STEP 1: Train one epoch\n",
    "    model, train_score = train_one_epoch(model, yolo, device)\n",
    "    \n",
    "    # STEP 2: Add TRAINING score to PAI tracker\n",
    "    # This creates the green line in the graph\n",
    "    GPA.pai_tracker.add_extra_score(train_score * 100, 'train')  # Convert to percentage\n",
    "    \n",
    "    # STEP 3: Validate\n",
    "    val_score = validate_model(model, yolo, device)\n",
    "    \n",
    "    # STEP 4: Add VALIDATION score to PAI tracker\n",
    "    # This creates the orange line and may trigger dendrite addition\n",
    "    model, restructured, training_complete = GPA.pai_tracker.add_validation_score(\n",
    "        val_score * 100,  # Convert to percentage\n",
    "        model\n",
    "    )\n",
    "    \n",
    "    # Move model back to device after potential restructuring\n",
    "    model = model.to(device)\n",
    "    yolo.model = model\n",
    "    \n",
    "    # STEP 5: If model was restructured (dendrites added), reset optimizer\n",
    "    if restructured:\n",
    "        print(\">>> MODEL RESTRUCTURED - Dendrites added! <<<\")\n",
    "        optimArgs['params'] = model.parameters()\n",
    "        optimizer, scheduler = GPA.pai_tracker.setup_optimizer(model, optimArgs, schedArgs)\n",
    "        \n",
    "        current_params = count_parameters(model)\n",
    "        print(f\"    New parameter count: {current_params / 1e6:.2f}M\")\n",
    "    \n",
    "    # Log progress\n",
    "    current_params = count_parameters(model)\n",
    "    history['train_scores'].append(train_score)\n",
    "    history['val_scores'].append(val_score)\n",
    "    history['params'].append(current_params)\n",
    "    \n",
    "    print(f\"  Train mAP50: {train_score:.4f}\")\n",
    "    print(f\"  Val mAP50:   {val_score:.4f}\")\n",
    "    print(f\"  Parameters:  {current_params / 1e6:.2f}M\")\n",
    "    \n",
    "    if training_complete:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"TRAINING COMPLETE - PerforatedAI optimization finished!\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    epoch += 1\n",
    "\n",
    "print(f\"\\nFinished after {epoch} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Save final graphs and results\n",
    "#\n",
    "# The PAI tracker automatically saves graphs, but we can also call it manually\n",
    "# The output will be at PAI/PAI.png (based on save_name)\n",
    "\n",
    "print(\"Saving final graphs...\")\n",
    "\n",
    "# PAI's save_graphs creates the multi-panel output matching Dendrite Recommendations\n",
    "try:\n",
    "    GPA.pai_tracker.save_graphs()\n",
    "    print(\"Graphs saved to PAI/PAI.png\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Graph saving encountered: {e}\")\n",
    "\n",
    "# Final results\n",
    "final_params = count_parameters(model)\n",
    "final_val_score = validate_model(model, yolo, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Baseline parameters:  {baseline_params / 1e6:.2f}M\")\n",
    "print(f\"Final parameters:     {final_params / 1e6:.2f}M\")\n",
    "print(f\"Parameter change:     {((final_params - baseline_params) / baseline_params) * 100:+.1f}%\")\n",
    "print(f\"Final validation mAP50: {final_val_score:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save results JSON\n",
    "results = {\n",
    "    'baseline': {\n",
    "        'params_M': baseline_params / 1e6\n",
    "    },\n",
    "    'dendritic': {\n",
    "        'params_M': final_params / 1e6,\n",
    "        'final_val_mAP50': final_val_score\n",
    "    },\n",
    "    'epochs_trained': epoch,\n",
    "    'history': {\n",
    "        'train_scores': history['train_scores'],\n",
    "        'val_scores': history['val_scores'],\n",
    "        'params': [p / 1e6 for p in history['params']]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('PAI/results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\nResults saved to PAI/results.json\")\n",
    "print(\"Graph output at PAI/PAI.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Display the generated graph\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "graph_path = 'PAI/PAI.png'\n",
    "\n",
    "if os.path.exists(graph_path):\n",
    "    print(\"Displaying PAI output graph:\")\n",
    "    print(\"(This should match the format in Dendrite Recommendations.pdf)\")\n",
    "    print()\n",
    "    \n",
    "    img = mpimg.imread(graph_path)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nGraph interpretation:\")\n",
    "    print(\"- Green line: Training scores\")\n",
    "    print(\"- Orange line: Validation scores\")\n",
    "    print(\"- Vertical blue/red bars: Epochs where dendrites were added\")\n",
    "    print(\"- Blue/Red continuation lines: What would have happened without dendrites\")\n",
    "else:\n",
    "    print(f\"Graph not found at {graph_path}\")\n",
    "    print(\"This may mean training didn't complete or PAI wasn't configured correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Download files\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"Downloading output files...\")\n",
    "    \n",
    "    if os.path.exists('PAI/PAI.png'):\n",
    "        files.download('PAI/PAI.png')\n",
    "    \n",
    "    if os.path.exists('PAI/results.json'):\n",
    "        files.download('PAI/results.json')\n",
    "    \n",
    "    # Also download any CSV files PAI generates\n",
    "    for f in os.listdir('PAI'):\n",
    "        if f.endswith('.csv'):\n",
    "            files.download(f'PAI/{f}')\n",
    "    \n",
    "    print(\"Done! Check your downloads.\")\n",
    "else:\n",
    "    print(\"Files are available in the PAI/ directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
