{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Dendritic YOLOv8 - Object Detection with Dendritic Optimization\n\nThis notebook demonstrates integrating PerforatedAI's dendritic optimization into YOLOv8n.\n\n**Updates (Jan 25, 2026):**\n- ✅ Uses proper duplicate handling (no monkey patching)\n- ✅ Based on official yolo-dendritic reference implementation\n- ✅ Runs completely non-interactively in Colab\n- ✅ Uses official PerforatedAI API (`append_module_names_to_not_save`)\n\n**Graph Output**: This notebook produces the correct PAI graph format:\n- Green line: Training scores\n- Orange line: Validation scores  \n- Blue/Red lines: What would have happened without dendrites\n- Vertical bars: Epochs where dendrites were added\n\n## Setup\n1. **Runtime → Change runtime type → GPU (T4 or L4)**\n2. **Run all cells in order**\n3. Training runs automatically - no manual interaction needed!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies\n",
    "!pip install -q ultralytics\n",
    "!pip install -q perforatedai==3.0.7\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "import json\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# PerforatedAI imports\n",
    "from perforatedai import globals_perforatedai as GPA\n",
    "from perforatedai import utils_perforatedai as UPA\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Helper functions\ndef count_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef auto_exclude_yolov8_duplicates(model):\n    \"\"\"\n    Pre-configure PerforatedAI to skip YOLOv8's shared module pointers.\n    \n    Based on the reference implementation in Examples/hackathonProject/yolo-dendritic/\n    This is the PROPER way to avoid debugger prompts - uses official API, no hacks!\n    \n    YOLOv8 shares activation function instances for memory efficiency (~25-30 shared refs).\n    This function tells PerforatedAI which duplicates to skip BEFORE initialize_pai().\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"Pre-configuring PerforatedAI for YOLOv8 shared modules...\")\n    print(\"=\"*70)\n    \n    # Step 1: Find ALL duplicate module pointers automatically\n    seen = {}\n    excluded = []\n    \n    for name, mod in model.named_modules():\n        mid = id(mod)\n        if mid in seen:\n            GPA.pc.append_module_names_to_not_save([name])\n            excluded.append(name)\n        else:\n            seen[mid] = name\n    \n    # Step 2: Exclude known YOLOv8 activation patterns\n    # Backbone layers\n    for i in range(1, 23):\n        for suffix in ['.act', '.default_act', '.cv1.act', '.cv1.default_act',\n                       '.cv2.act', '.cv2.default_act', '.conv.act', '.conv.default_act']:\n            GPA.pc.append_module_names_to_not_save([f\".model.{i}{suffix}\"])\n    \n    # C2f nested modules\n    for i in range(1, 23):\n        for m_idx in range(10):\n            for cv in ['cv1', 'cv2']:\n                GPA.pc.append_module_names_to_not_save([f\".model.{i}.m.{m_idx}.{cv}.act\"])\n                GPA.pc.append_module_names_to_not_save([f\".model.{i}.m.{m_idx}.{cv}.default_act\"])\n    \n    # Detection head\n    for cv in [\"cv2\", \"cv3\"]:\n        for i in range(3):\n            for j in range(3):\n                GPA.pc.append_module_names_to_not_save([f\".model.22.{cv}.{i}.{j}.act\"])\n                GPA.pc.append_module_names_to_not_save([f\".model.22.{cv}.{i}.{j}.default_act\"])\n    \n    print(f\"✓ Pre-configured {len(excluded)} duplicate exclusions\")\n    print(\"✓ Model ready for non-interactive PAI initialization\")\n    print(\"=\"*70 + \"\\n\")\n    \n    return len(excluded)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: Load model and initialize PerforatedAI\nprint(\"Loading YOLOv8n...\")\nyolo = YOLO('yolov8n.pt')\nmodel = yolo.model\n\nbaseline_params = count_params(model)\nprint(f\"Baseline parameters: {baseline_params:,}\\n\")\n\n# CRITICAL: Pre-configure duplicate exclusions BEFORE initialize_pai()\n# This is the proper solution from yolo-dendritic reference implementation\n# Uses official PerforatedAI API - no monkey patching needed!\nauto_exclude_yolov8_duplicates(model)\n\n# Configure PerforatedAI\nprint(\"Configuring PerforatedAI...\")\nGPA.pc.set_testing_dendrite_capacity(False)\nGPA.pc.set_verbose(True)\nGPA.pc.set_unwrapped_modules_confirmed(True)\nGPA.pc.set_max_dendrites(5)  # Allow up to 5 dendrite addition cycles\nprint(\"[OK] PerforatedAI configured\\n\")\n\n# Create output directory\nos.makedirs('PAI', exist_ok=True)\n\n# Initialize PAI - should now run WITHOUT debugger prompts!\nprint(\"Initializing PerforatedAI (non-interactive)...\")\nmodel = UPA.initialize_pai(\n    model,\n    doing_pai=True,\n    save_name='PAI',  # Output will be PAI/PAI.png\n    maximizing_score=True,  # We maximize mAP\n    making_graphs=True\n)\n\nmodel = model.to(device)\nyolo.model = model\nprint(\"[OK] PerforatedAI initialized without debugger prompts!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: Setup optimizer through PAI tracker\nGPA.pai_tracker.set_optimizer(optim.Adam)\nGPA.pai_tracker.set_scheduler(ReduceLROnPlateau)\n\nlr = 0.001\n\n# CORRECTED: Let GPA.pai_tracker.setup_optimizer manage parameters automatically\n# It knows which parameters should be trainable within the PAI framework\noptimArgs = {'lr': lr}  # Removed 'params' key - let PAI tracker handle it\nschedArgs = {'mode': 'max', 'patience': 5}\n\n# GPA.pai_tracker.setup_optimizer will automatically identify trainable parameters\noptimizer, scheduler = GPA.pai_tracker.setup_optimizer(model, optimArgs, schedArgs)\n\nprint(\"✓ Optimizer configured through PAI tracker\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Training loop with PROPER PAI integration\n#\n# KEY for correct graph output:\n# 1. add_extra_score(train_score, 'train') -> Creates GREEN line\n# 2. add_validation_score(val_score, model) -> Creates ORANGE line & triggers dendrites\n# 3. Continue until training_complete is True\n# 4. Reset optimizer when model is restructured\n\nMAX_EPOCHS = 100\nDATA = 'coco128.yaml'\nBATCH = 16\nIMGSZ = 640\n\nprint(f\"Starting training with PerforatedAI integration...\")\nprint(f\"Baseline parameters: {baseline_params:,}\")\nprint(\"=\"*60)\n\nepoch = 0\ntraining_complete = False\nhistory = {'train': [], 'val': [], 'params': []}\n\nwhile not training_complete and epoch < MAX_EPOCHS:\n    print(f\"\\nEpoch {epoch + 1}/{MAX_EPOCHS}\")\n    \n    # Train one epoch\n    yolo.model = model\n    results = yolo.train(\n        data=DATA,\n        epochs=1,\n        imgsz=IMGSZ,\n        batch=BATCH,\n        device=device,\n        exist_ok=True,\n        verbose=False,\n        project='runs/train',\n        name='dendritic'\n    )\n    model = yolo.model\n    \n    # Get training score\n    train_map50 = float(results.results_dict.get('metrics/mAP50(B)', 0))\n    \n    # CRITICAL: Add TRAINING score (creates green line)\n    GPA.pai_tracker.add_extra_score(train_map50 * 100, 'train')\n    \n    # Validate\n    val_metrics = yolo.val(verbose=False)\n    val_map50 = float(val_metrics.box.map50)\n    val_map50_95 = float(val_metrics.box.map)\n    \n    # CRITICAL: Add VALIDATION score (creates orange line, may add dendrites)\n    model, restructured, training_complete = GPA.pai_tracker.add_validation_score(\n        val_map50_95 * 100, model\n    )\n    model = model.to(device)\n    yolo.model = model\n    \n    # Log\n    current_params = count_params(model)\n    history['train'].append(train_map50)\n    history['val'].append(val_map50_95)\n    history['params'].append(current_params)\n    \n    print(f\"  Train mAP@0.5: {train_map50:.4f}\")\n    print(f\"  Val mAP@0.5:   {val_map50:.4f}\")\n    print(f\"  Val mAP@0.5:0.95: {val_map50_95:.4f}\")\n    print(f\"  Parameters: {current_params:,}\")\n    \n    # If restructured, reset optimizer (PAI tracker manages parameters)\n    if restructured:\n        print(\"\\n>>> DENDRITES ADDED! Model restructured <<<\")\n        # Let PAI tracker handle parameters - don't pass explicit params\n        optimArgs = {'lr': lr}\n        optimizer, scheduler = GPA.pai_tracker.setup_optimizer(model, optimArgs, schedArgs)\n    \n    if training_complete:\n        print(\"\\n\" + \"=\"*60)\n        print(\"TRAINING COMPLETE!\")\n        print(\"=\"*60)\n    \n    epoch += 1\n\nprint(f\"\\nFinished after {epoch} epochs\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save graphs and results\n",
    "print(\"Saving PAI graphs...\")\n",
    "try:\n",
    "    GPA.pai_tracker.save_graphs()\n",
    "    print(\"Graphs saved to PAI/PAI.png\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: {e}\")\n",
    "\n",
    "# Final results\n",
    "final_params = count_params(model)\n",
    "final_val = yolo.val(verbose=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Baseline parameters:  {baseline_params:,}\")\n",
    "print(f\"Final parameters:     {final_params:,}\")\n",
    "print(f\"Parameter change:     {((final_params - baseline_params) / baseline_params) * 100:+.1f}%\")\n",
    "print(f\"Final mAP@0.5:        {final_val.box.map50:.4f}\")\n",
    "print(f\"Final mAP@0.5:0.95:   {final_val.box.map:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'baseline_params': baseline_params,\n",
    "    'final_params': final_params,\n",
    "    'final_mAP50': float(final_val.box.map50),\n",
    "    'final_mAP50_95': float(final_val.box.map),\n",
    "    'epochs_trained': epoch,\n",
    "    'history': history\n",
    "}\n",
    "with open('PAI/results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"\\nResults saved to PAI/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Display the PAI graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "if os.path.exists('PAI/PAI.png'):\n",
    "    print(\"PAI Output Graph (matches Dendrite Recommendations format):\")\n",
    "    print()\n",
    "    display(Image('PAI/PAI.png'))\n",
    "    print(\"\\nGraph interpretation:\")\n",
    "    print(\"- Green line: Training scores\")\n",
    "    print(\"- Orange line: Validation scores\")\n",
    "    print(\"- Vertical bars: Dendrite addition epochs\")\n",
    "    print(\"- Blue/Red lines: What would have happened without dendrites\")\n",
    "else:\n",
    "    print(\"Graph not found. Ensure training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Download results\n",
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    if os.path.exists('PAI/PAI.png'):\n",
    "        files.download('PAI/PAI.png')\n",
    "    if os.path.exists('PAI/results.json'):\n",
    "        files.download('PAI/results.json')\n",
    "    \n",
    "    # Download CSVs\n",
    "    for f in os.listdir('PAI'):\n",
    "        if f.endswith('.csv'):\n",
    "            files.download(f'PAI/{f}')\n",
    "    \n",
    "    print(\"Files downloaded!\")\n",
    "except:\n",
    "    print(\"Files are in PAI/ directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}