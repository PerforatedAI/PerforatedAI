# Perforated NeuroShrink

## Intro

Perforated NeuroShrink demonstrates dendritic optimization using the official PerforatedAI PyTorch framework. The project shows how neural networks can continue improving after training plateaus by dynamically adding dendritic computation paths inspired by biological neurons.

This submission strictly follows the official PerforatedAI hackathon structure and focuses on correct framework usage, reproducibility, and understanding the dendritic training lifecycle.

### Team

Vishal Prakash — AI & Data Science Engineer  
GitHub: https://github.com/vishalprakash0307

---

## Project Impact

Traditional neural networks often stop improving after a fixed number of epochs. Dendritic optimization shows that adaptive restructuring can unlock additional performance without changing the dataset or architecture.

This enables:
- Higher accuracy after plateau
- Adaptive computation without extra data
- Better efficiency for edge and low-resource environments

This is especially impactful for OCR, document processing, and embedded AI systems.

---

## How We Built It

- Used a CNN trained on the MNIST dataset
- Integrated the official PerforatedAI API
- Tracked validation performance using the PAI tracker
- Automatically added dendrites after plateau detection
- Reinitialized the optimizer after each restructuring
- Continued training until `training_complete == True`
- Generated the required PAI output graph for verification

---

## Usage Instructions

### Installation

pip install -r requirements.txt

### Run Training and Generate Required Graph

python train_generate_graph.py

The PerforatedAI output graph is generated automatically at:

PAI/PAI.png

---

## Results

### Baseline Model (Without Dendrites)

Validation Accuracy: ~98.6%  
Architecture: Standard CNN  

### Dendritic Model (With PerforatedAI)

Validation Accuracy: ~99.5%  
Dendrites added after training plateau  

### Remaining Error Reduction

Baseline error: 1.4%  
Dendritic error: 0.5%  

This corresponds to approximately **64% remaining error reduction**, achieved only after dendritic restructuring.

---

## Raw Results Graph (Required)

The following graph is automatically generated by the PerforatedAI framework and verifies correct dendrite insertion and training behavior.

<img width="2800" height="1400" alt="PAI" src="https://github.com/user-attachments/assets/beab9279-810a-4357-b576-d91f620c4abb" />


Key indicators:
- Vertical blue lines mark dendrite insertion points
- Validation accuracy improves after restructuring
- Training proceeds until completion

---

## What We Learned

- Optimizer reinitialization after restructuring is critical
- Training must continue until `training_complete` is triggered
- Dendritic optimization is most effective after learning plateaus

---

## What’s Next

- Apply dendritic optimization to compressed architectures
- Extend experiments to larger datasets
- Explore edge deployment and compute efficiency gains

---

## Additional Notes

This project:
- Uses the official PerforatedAI API
- Does not modify internal library code
- Focuses on correctness, reproducibility, and lifecycle understanding
